% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/F_fdrCorrect.R
\name{fdrCorrect}
\alias{fdrCorrect}
\title{Perform simultaneous inference, correcting for correlation between tests.}
\usage{
fdrCorrect(Y, x, B = 500L, test = "wilcox.test", argList = list(),
  testPfun = "pwilcox", testPargs = list(m = table(x)[1], n =
  table(x)[2]), extractFun = "identity", z0Quant = pnorm(c(-1, 1)),
  gridsize = 801L, weightStrat = "LH", maxIter = 1000L,
  tol = 1e-04, cPerm = FALSE, nBins = 82L, binEdges = c(-4.1, 4.1),
  center = FALSE, zVals = NULL, estP0args = list(z0quantRange =
  seq(0.05, 0.45, 0.0125), smooth.df = 3))
}
\arguments{
\item{Y}{the matrix of sequencing counts}

\item{x}{a grouping factor}

\item{B}{the number of permutations}

\item{test}{Character string, giving the name of the function
to test for differential absolute abundance.
Must accept the formula interface}

\item{argList}{A list of arguments, passed on to the testing function}

\item{testPfun}{the name of the distribution function of the test statistic}

\item{testPargs}{A list of arguments passed on to testPfun}

\item{extractFun}{A function to extract the test statistics
 from the fit object. Defaults to the identity() function, i.e. assuming that
the test function immediately returns the test statistic}

\item{z0Quant}{A vector of length 2 of quantiles of the null distribution,
in between which only null values are expected}

\item{gridsize}{The number of bins for the kernel density estimates}

\item{weightStrat}{A character vector, indicating the weighting strategy.
Either "LH" for likelihoods based on the central region,
or "LHw" for weighted likelihoods}

\item{maxIter}{An integer, the maximum number of iterations in the estimation
of the null distribution}

\item{tol}{The tolerance for the infinity norm of the central borders
in the iterative procedure}

\item{cPerm}{A boolean, should the covariance matrix
of the binned counts be returned?}

\item{nBins}{The number of bins for the binning of the test statistic
in the calculation of the correlation matrix}

\item{binEdges}{The edges of the furthest bins}

\item{center}{A boolean, should observations be centered
in each group prior to permuations? See details.}

\item{zVals}{An optional list of observed (zValObs) and
permutation (zValsPerm) z-values. If supplied, the calculation
   of the observed and permutation test statistics is skipped
   and the algorithm proceeds with calculation
   of the consensus null distribution}

\item{estP0args}{A list of arguments passed on to the estP0 function}
}
\value{
A list with entries
\item{zValsMat}{Permutation Z-values}
\item{zValObs}{Observed Z-values}
\item{Cperm}{(optional) An estimated covariance matrix
 of binned test statistics}
\item{weightStrat}{The weighting strategy }
\item{Fdr, fdr}{The estimated tail-area and local false discovery rates}
\item{consensus}{The consensus null distribution}
}
\description{
Perform simultaneous inference, correcting for correlation between tests.
}
\details{
Efron (2007) centers the observations in each group prior
 to permutation. As permutations will remove any genuine group differences
  anyway, we skip this step by default.
}
\examples{
p = 100; n = 50
x = rep(c(0,1), each = n/2)
mat = cbind(
matrix(rnorm(n*p/10, mean = 5+x),n,p/10), #DA
matrix(rnorm(n*p*9/10, mean = 5),n,p*9/10) #Non DA
)
fdrRes = fdrCorrect(mat, x)
fdrRes$p0
#Indeed close to 0.9

#With another type of test
fdrResLm = fdrCorrect(mat, x, test = "lm", B = 5e1,
extractFun = function(x){summary(x)$coef["x1","t value"]})
}
